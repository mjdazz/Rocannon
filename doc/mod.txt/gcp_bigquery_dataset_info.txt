SYNOPSIS                   *gcp_bigquery_dataset_info*

     • Gather info for GCP Dataset
     • This module was called gcp_bigquery_dataset_facts before Ansible 2.9. The usage has not changed.

   Aliases: gcp_bigquery_dataset_facts

REQUIREMENTS                   *gcp_bigquery_dataset_info-requirements*

   The below requirements are needed on the host that executes this module.

     • python >= 2.6
     • requests >= 2.18.4
     • google-auth >= 1.3.0

PARAMETERS                   *gcp_bigquery_dataset_info-parameters*

          Parameter           Choices/Defaults                                                                         Comments
                              Choices:
   auth_kind                  • application      The type of credential used.
   string / required          • machineaccount
                              • serviceaccount
   env_type                                      Specifies which Ansible environment you're running this module within.
   string                                        This should not be set unless you know what you're doing.
                                                 This only alters the User Agent string for any API requests.
   project                                       The Google Cloud Platform project to use.
   string
   scopes                                        Array of scopes to be used.
   list
   service_account_contents                      The contents of a Service Account JSON file, either in a dictionary or as a JSON string that represents it.
   jsonarg
   service_account_email                         An optional service account email address if machineaccount is selected and the user does not wish to use the default email.
   string
   service_account_file                          The path of a Service Account JSON file if serviceaccount is selected as type.
   path

NOTES                   *gcp_bigquery_dataset_info-notes*

   Note

     • for authentication, you can set service_account_file using the c(gcp_service_account_file) env variable.
     • for authentication, you can set service_account_contents using the c(GCP_SERVICE_ACCOUNT_CONTENTS) env variable.
     • For authentication, you can set service_account_email using the GCP_SERVICE_ACCOUNT_EMAIL env variable.
     • For authentication, you can set auth_kind using the GCP_AUTH_KIND env variable.
     • For authentication, you can set scopes using the GCP_SCOPES env variable.
     • Environment variables values will only be used if the playbook values are not set.
     • The service_account_email and service_account_file options are mutually exclusive.

EXAMPLES                   *gcp_bigquery_dataset_info-examples*

 - name: get info on a dataset
   gcp_bigquery_dataset_info:
     project: test_project
     auth_kind: serviceaccount
     service_account_file: "/tmp/auth.pem"

RETURN VALUES                   *gcp_bigquery_dataset_info-return values*

   Common return values are documented here, the following are the fields unique to this module:

                Key               Returned                                                                        Description
   resources                      always   List of resources
   complex
     access                       success  An array of objects that define dataset access for one or more entities.
     complex
            domain                success  A domain to grant access to. Any users signed in with the domain specified will be granted the specified access .
            string
            groupByEmail          success  An email address of a Google Group to grant access to.
            string
            role                           Describes the rights granted to the user specified by the other member of the access object. Primitive, Predefined and custom roles are supported.
            string                success  Predefined roles that have equivalent primitive roles are swapped by the API to their Primitive counterparts, and will show a diff post-create. See
                                           [official docs](https://cloud.google.com/bigquery/docs/access-control).
                                           A special group to grant access to.
            specialGroup                   Possible values include: " `projectOwners`: Owners of the enclosing project.
            string                success  " `projectReaders`: Readers of the enclosing project.
                                           " `projectWriters`: Writers of the enclosing project.
                                           " `allAuthenticatedUsers`: All authenticated BigQuery users. .
            userByEmail           success  An email address of a user to grant access to. For example: [email protected] .
            string
            view                  success  A view from a different dataset to grant access to. Queries executed against that view will have read access to tables in this dataset. The role field is
            complex                        not required when this field is set. If that view is updated by any user, access to the view needs to be granted again via an update operation.
                    datasetId     success  The ID of the dataset containing this table.
                    string
                    projectId     success  The ID of the project containing this table.
                    string
                    tableId       success  The ID of the table. The ID must contain only letters (a-z, A-Z), numbers (0-9), or underscores. The maximum length is 1,024 characters.
                    string
     creationTime                 success  The time when this dataset was created, in milliseconds since the epoch.
     integer
     datasetReference             success  A reference that identifies the dataset.
     complex
            datasetId             success  A unique ID for this dataset, without the project name. The ID must contain only letters (a-z, A-Z), numbers (0-9), or underscores. The maximum length is
            string                         1,024 characters.
            projectId             success  The ID of the project containing this dataset.
            string
                                           The default partition expiration for all partitioned tables in the dataset, in milliseconds.
                                           Once this property is set, all newly-created partitioned tables in the dataset will have an `expirationMs` property in the `timePartitioning` settings set
     defaultPartitionExpirationMs          to this value, and changing the value will only affect new tables, not existing ones. The storage in a partition will have an expiration time of its
     integer                      success  partition time plus this value.
                                           Setting this property overrides the use of `defaultTableExpirationMs` for partitioned tables: only one of `defaultTableExpirationMs` and
                                           `defaultPartitionExpirationMs` will be used for any new partitioned table. If you provide an explicit `timePartitioning.expirationMs` when creating or
                                           updating a partitioned table, that value takes precedence over the default partition expiration time indicated by this property.
                                           The default lifetime of all tables in the dataset, in milliseconds.
                                           The minimum value is 3600000 milliseconds (one hour).
     defaultTableExpirationMs              Once this property is set, all newly-created tables in the dataset will have an `expirationTime` property set to the creation time plus the value in this
     integer                      success  property, and changing the value will only affect new tables, not existing ones. When the `expirationTime` for a given table is reached, that table will
                                           be deleted automatically.
                                           If a table's `expirationTime` is modified or removed before the table expires, or if you provide an explicit `expirationTime` when creating a table, that
                                           value takes precedence over the default expiration time indicated by this property.
     description                  success  A user-friendly description of the dataset.
     string
     etag                         success  A hash of the resource.
     string
     friendlyName                 success  A descriptive name for the dataset.
     string
     id                           success  The fully-qualified unique name of the dataset in the format projectId:datasetId. The dataset name without the project name is given in the datasetId
     string                                field .
     labels                       success  The labels associated with this dataset. You can use these to organize and group your datasets .
     dictionary
     lastModifiedTime             success  The date when this dataset or any of its tables was last modified, in milliseconds since the epoch.
     integer
                                           The geographic location where the dataset should reside.
                                           See [official docs](https://cloud.google.com/bigquery/docs/dataset-locations).
                                           There are two types of locations, regional or multi-regional. A regional location is a specific geographic place, such as Tokyo, and a multi-regional
     location                              location is a large geographic area, such as the United States, that contains at least two geographic places.
     string                       success  Possible regional values include: `asia-east1`, `asia-northeast1`, `asia-southeast1`, `australia-southeast1`, `europe-north1`, `europe-west2` and
                                           `us-east4`.
                                           Possible multi-regional values: `EU` and `US`.
                                           The default value is multi-regional location `US`.
                                           Changing this forces a new resource to be created.
     name                         success  Dataset name.
     string

STATUS                   *gcp_bigquery_dataset_info-status*

     • This module is not guaranteed to have a backwards compatible interface. [preview]
     • This module is maintained by the Ansible Community. [community]

     • Google Inc. (@googlecloudplatform)

   Hint

   If you notice any issues in this documentation, you can edit this document to improve it.

   ══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════

MORE INFO                          *gcp_bigquery_dataset_info-moreinfo*
>
All arguments are omni-completed, but if you really want to see the online docs:
https://docs.ansible.com/ansible/latest/modules/gcp_bigquery_dataset_info_module.html
